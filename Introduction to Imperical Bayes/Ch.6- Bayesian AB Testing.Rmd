---
title: "R Notebook"
output: html_notebook
---
In this chapter we will examine a situation in which we are comparing two players. One player may have a higher average, but the other player may have a more narrow spread. So their distributions may overlap showing some probibility that the palyer  with the lower average may actually have the higher true average. This is an example of **A/B testing**.

##6.1  setting up the 
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
NBA_2016 <- read_csv("~/Emekas Documents/R-Directory/NBA 2016.csv")
```


```{r}
shooting <- NBA_2016 %>%
  filter(FGA > 0) %>%
  mutate(FGN = FGA - FGM, average = FGM/FGA) %>%
  dplyr::select(Player, Team, PS, FGM, FGN, FGA, average)

# from chapter 3
alpha0 <- 39.23353 
beta0 <- 48.72738 

shooting_eb <- shooting %>%
  mutate(eb_estimate = ((FGM + alpha0) / (FGA + alpha0 + beta0)),
         alpha1 = alpha0 + FGM, 
         beta1 = beta0 + FGN)

shooting_eb <- shooting_eb %>%
  mutate(alpha1 = alpha0 + FGM, beta1 = beta0 + FGN)
```

##6.2 Comparing posterior distributions
Here I'm going to compare two playes to create the situation proposed earlier. This A/B test will compare LeBron James who has a lower FG% but more evidence (more narrow distribution) and Tristan Thompson who has a higher FG%, but less evidence (Wider distribution).
```{r}
lbj <- shooting_eb %>% filter(Player == "james,lebron")
tt <- shooting_eb %>% filter(Player == "thompson,tristan")
two_players <- bind_rows(lbj, tt)
```


```{r}
theme_set(theme_bw())

two_players %>%
  crossing(x = seq(.3, .7, .00025)) %>%
  mutate(density = dbeta(x, alpha1, beta1)) %>%
  ggplot(aes(x, density, color = Player)) +
  geom_line() +
  labs(x = "Field Goal average", color = "")
```
You can see by the overlapping region that there is some probibility that LeBron has the higher field goal average

But how do we know the probibility of one beta distribution is higher than the other? THere are four ways.

* Simulation of posterior draws
* Numerical integration
* Closed-form solution
* Closed-form approximation


## 6.2.1 Simulation of posterior draws
Here we will do a simulation by using each players alpha1 and beta1 and draw a million "items" using rbeta.
```{r}
lbj_simulation <- rbeta(1e6, lbj$alpha1, lbj$beta1)
tt_simulation <- rbeta(1e6, tt$alpha1, tt$beta1)

sim <- mean(lbj_simulation > tt_simulation)
sim
```
This means there is a 2.7% chance that Lebron has a higher FG% than Tristian Thompson. That's still some bit of a chance though.


## 6.2.2 Integration
We are going to combine these two independent distributions into one joint distribution. It is a density over pairs of x and y. This will be displayed as a word cloud.

```{r}
x <- seq(.3, .7, .0002)
crossing(lbj_x = x, tt_x = x) %>%
  mutate(lbj_density = dbeta(lbj_x, lbj$alpha1, lbj$beta1),
         tt_density = dbeta(tt_x, tt$alpha1, tt$beta1),
         joint = lbj_density * tt_density) %>%
  ggplot(aes(lbj_x, tt_x, fill = joint)) +
  geom_tile() +
  geom_abline() + 
  scale_fill_gradient2(low = "white", high = "red") +
  labs(x = "LeBron Field Goal Average",
       y = "Tristan Field Goal Average",
       fill = "Joint Density") +
  theme(legend.position = "none")


d <- .0002
limits <- seq(.3, .7, d)

sum(outer(limits, limits, function(x, y) {
  (x > y) *
    dbeta(x, lbj$alpha1, lbj$beta1) *
    dbeta(y, tt$alpha1, tt$beta1) *
    d^2
}))

```
My plot looks different than the one in the book. First, I did far fewer simulations. second, there is a much lower probibility that LeBron has a higher FG% than Tristan so the vast majority of hte points lie above the line. The example in the book was nearly 50/50.


## 6.2.3 Closed-form SOlution
There's an equation for this. Best to just look in the book. pg.50
```{r}
h <- function(alpha_a, beta_a,
              alpha_b, beta_b) {
  j <- seq.int(0, round(alpha_b) - 1)
  log_vals <- (lbeta(alpha_a + j, beta_a + beta_b) - log(beta_b + j) -
               lbeta(1 + j, beta_b) - lbeta(alpha_a, beta_a))
  1 - sum(exp(log_vals))
}

h(lbj$alpha1, lbj$beta1,
  tt$alpha1, tt$beta1)
```
This provides an exact solution. There are some drawbacks though.

* Not every problem has a solution like this. And even if it does, we may not know it. That's why it's worth knowing how to run a simulation. (If nothing else, they let us check our math!)

* This solution is slow for large B, and not straightforward to vectorize: notice that term that iterates from 0 to B ???? 1. If we run A/B tests with thousands of clicks, this step is going to constrain us (though it's still usually faster than simulation or integration).


## 6.2.4 Closed-form Approximation
This is only an approximation, but it's much faster.

```{r}
two_players %>%
  mutate(mu = alpha1 / (alpha1 + beta1),
         var = alpha1 * beta1 / ((alpha1 + beta1) ^ 2 * (alpha1 + beta1 + 1))) %>%
  crossing(x = seq(.3, .8, .00025)) %>%
  mutate(density = dbeta(x, alpha1, beta1),
         normal = dnorm(x, mu, sqrt(var))) %>%
  ggplot(aes(x, density, group = Player)) +
  geom_line(aes(color = Player)) +
  geom_line(lty = 2)

h_approx <- function(alpha_a, beta_a, alpha_b, beta_b) {
  u1 <- alpha_a / (alpha_a + beta_a)
  u2 <- alpha_b / (alpha_b + beta_b)
  var1 <- (alpha_a * beta_a) /
    ((alpha_a + beta_a) ^ 2 * (alpha_a + beta_a + 1))
  var2 <- (alpha_b * beta_b) /
    ((alpha_b + beta_b) ^ 2 * (alpha_b + beta_b + 1))
  pnorm(0, u2 - u1, sqrt(var1 + var2))
}

h_approx(lbj$alpha1, lbj$beta1, tt$alpha1, tt$beta1)
```
The downside to this is that when alpha or beta is low, the normal approximation of hte beta doesn't fit well.

## 6.3 Confidence Intervals
Here were going to compare two proportions. Lebrons and Tristans (field goals made)/(field goals attempted). This will be done in a chi-square as shown.
```{r}
prop.test(two_players$FGM, two_players$FGA)
```
THe book had two plays with very close averages. His p value was .70. very insiginificant. My two proportions are far apart. So my p value is .027. Significant at the .05 level.



```{r}
credible_interval_approx <- function(a, b, c, d) {
  u1 <- a / (a + b)
  u2 <- c / (c + d)
  var1 <- a * b / ((a + b) ^ 2 * (a + b + 1))
  var2 <- c * d / ((c + d) ^ 2 * (c + d + 1))
  
  mu_diff <- u2 - u1
  sd_diff <- sqrt(var1 + var2)
  
  data_frame(posterior = pnorm(0, mu_diff, sd_diff),
             estimate = mu_diff,
             conf.low = qnorm(.025, mu_diff, sd_diff),
             conf.high = qnorm(.975, mu_diff, sd_diff))
}

credible_interval_approx(lbj$alpha1, lbj$beta1, 
                         tt$alpha1, tt$beta1)
```



